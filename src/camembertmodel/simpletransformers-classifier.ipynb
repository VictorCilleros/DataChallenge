{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-15T13:29:42.993635Z","iopub.execute_input":"2023-02-15T13:29:42.994564Z","iopub.status.idle":"2023-02-15T13:29:43.044208Z","shell.execute_reply.started":"2023-02-15T13:29:42.994470Z","shell.execute_reply":"2023-02-15T13:29:43.043190Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/mltfc-gpt/X_test_gpt.csv\n/kaggle/input/mltfc-gpt/X_train_gpt.csv\n/kaggle/input/dictionnaire-french-words/dictionnaire.txt\n/kaggle/input/mlftc/Category description.pdf\n/kaggle/input/mlftc/X_test.csv\n/kaggle/input/mlftc/y_train.csv\n/kaggle/input/mlftc/nonlabeled_data.csv\n/kaggle/input/mlftc/X_train.csv\n/kaggle/input/mlftc/sampleSubmission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Installation simpletransformers","metadata":{}},{"cell_type":"code","source":"!pip3 install simpletransformers","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:29:43.046557Z","iopub.execute_input":"2023-02-15T13:29:43.047535Z","iopub.status.idle":"2023-02-15T13:30:03.206859Z","shell.execute_reply.started":"2023-02-15T13:29:43.047493Z","shell.execute_reply":"2023-02-15T13:30:03.205349Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting simpletransformers\n  Downloading simpletransformers-0.63.9-py3-none-any.whl (250 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.5/250.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (0.1.97)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (0.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (2.28.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (2021.11.10)\nRequirement already satisfied: wandb>=0.10.32 in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (0.12.21)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (1.7.3)\nCollecting streamlit\n  Downloading streamlit-1.18.1-py2.py3-none-any.whl (9.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.47.0 in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (4.64.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (1.21.6)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (4.20.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (1.3.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (1.0.2)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (2.6.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (2.1.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (23.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (6.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (3.7.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (0.10.1)\nRequirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (1.0.11)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (1.14.0)\nRequirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (1.15.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.2)\nRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (3.19.4)\nRequirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (2.3)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (59.8.0)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.3)\nRequirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.27)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (2022.12.7)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (2023.1.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (0.3.6)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (5.0.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (3.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (3.8.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->simpletransformers) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->simpletransformers) (2022.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->simpletransformers) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->simpletransformers) (3.1.0)\nCollecting validators>=0.2\n  Downloading validators-0.20.0.tar.gz (30 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: semver in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (2.13.0)\nRequirement already satisfied: pympler>=0.9 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (1.0.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (9.1.1)\nRequirement already satisfied: tzlocal>=1.1 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (4.2)\nRequirement already satisfied: cachetools>=4.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (4.2.4)\nCollecting pydeck>=0.1.dev5\n  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (0.10.2)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (12.6.0)\nRequirement already satisfied: altair>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (4.2.2)\nCollecting watchdog\n  Downloading watchdog-2.2.1-py3-none-manylinux2014_x86_64.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tornado>=6.0.3 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (6.1)\nRequirement already satisfied: blinker>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (1.4)\nRequirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (4.1.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (1.8.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.4.6)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (1.51.1)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.6.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (1.35.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.37.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.15.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (3.3.7)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (2.2.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (4.6.1)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.11.2)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (21.4.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (0.13.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (1.3.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (6.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (1.7.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->simpletransformers) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->simpletransformers) (4.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (1.3.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.6.0->simpletransformers) (3.8.0)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.11.0->streamlit->simpletransformers) (2.14.0)\nRequirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.11.0->streamlit->simpletransformers) (0.9.1)\nRequirement already satisfied: backports.zoneinfo in /opt/conda/lib/python3.7/site-packages (from tzlocal>=1.1->streamlit->simpletransformers) (0.2.1)\nRequirement already satisfied: pytz-deprecation-shim in /opt/conda/lib/python3.7/site-packages (from tzlocal>=1.1->streamlit->simpletransformers) (0.1.0.post0)\nRequirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from validators>=0.2->streamlit->simpletransformers) (5.1.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard->simpletransformers) (2.1.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb>=0.10.32->simpletransformers) (3.0.5)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (0.18.1)\nRequirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (5.10.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (3.2.0)\nRequirement already satisfied: tzdata in /opt/conda/lib/python3.7/site-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit->simpletransformers) (2022.7)\nBuilding wheels for collected packages: seqeval, validators\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=a3ed574d10b36e09ebe3c8909705d4894c937ac2315aa6e27a074fbdae55608e\n  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n  Building wheel for validators (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=288ec7098556b71880a9910504a8fa15aabb6cc2ae273cf3aa81f2bff4ac99a5\n  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\nSuccessfully built seqeval validators\nInstalling collected packages: watchdog, validators, pydeck, seqeval, streamlit, simpletransformers\nSuccessfully installed pydeck-0.8.0 seqeval-1.2.2 simpletransformers-0.63.9 streamlit-1.18.1 validators-0.20.0 watchdog-2.2.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install openai","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:03.209396Z","iopub.execute_input":"2023-02-15T13:30:03.209865Z","iopub.status.idle":"2023-02-15T13:30:40.288818Z","shell.execute_reply.started":"2023-02-15T13:30:03.209801Z","shell.execute_reply":"2023-02-15T13:30:40.287659Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-0.26.5.tar.gz (55 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.28.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.1.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.14)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.7.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (21.4.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.0)\nBuilding wheels for collected packages: openai\n  Building wheel for openai (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67596 sha256=db8043e990648353c67132bd4351c9b38084dc43e55c953c835af5b69f9d5fd3\n  Stored in directory: /root/.cache/pip/wheels/71/cc/39/e215726261759bc158d31178f0ff0adab8111cc1b1d2806ce4\nSuccessfully built openai\nInstalling collected packages: openai\nSuccessfully installed openai-0.26.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:40.291795Z","iopub.execute_input":"2023-02-15T13:30:40.292498Z","iopub.status.idle":"2023-02-15T13:30:54.351444Z","shell.execute_reply.started":"2023-02-15T13:30:40.292458Z","shell.execute_reply":"2023-02-15T13:30:54.350225Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n  Cloning https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git to /tmp/pip-req-build-ybmlsqca\n  Running command git clone --filter=blob:none --quiet https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git /tmp/pip-req-build-ybmlsqca\n  Resolved https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git to commit bc0ebd0135a6cc78f48ddf184069b4c0b9c017d8\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: FrenchLefffLemmatizer\n  Building wheel for FrenchLefffLemmatizer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for FrenchLefffLemmatizer: filename=FrenchLefffLemmatizer-0.3-py3-none-any.whl size=3533528 sha256=291c3951358fa7a520521ecbeadca2d511c912011a7a2215ce6b8acad4000c06\n  Stored in directory: /tmp/pip-ephem-wheel-cache-zencfp6i/wheels/ba/24/e1/a774b7bba29a14b3f6b291d16e92563c745aa4f4d6901a0af7\nSuccessfully built FrenchLefffLemmatizer\nInstalling collected packages: FrenchLefffLemmatizer\nSuccessfully installed FrenchLefffLemmatizer-0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from pathlib import Path\nLM_PATH = Path('/kaggle/working/Model/fine-tuned-corpus')\nLM_PATH_BEST = Path('/kaggle/working/Model/fine-tuned-corpus/best-model')\nCLASSIF_PATH = Path('/kaggle/working/Model/fine-tuned-classifier')\nCLASSIF_PATH_BEST = Path('/kaggle/working/Model/fine-tuned-classifier/best-model')","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:54.353701Z","iopub.execute_input":"2023-02-15T13:30:54.354159Z","iopub.status.idle":"2023-02-15T13:30:54.362872Z","shell.execute_reply.started":"2023-02-15T13:30:54.354083Z","shell.execute_reply":"2023-02-15T13:30:54.361993Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"import os\nimport openai\nopenai.api_key = \"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\"\nmodel_engine = \"davinci\"","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:54.364471Z","iopub.execute_input":"2023-02-15T13:30:54.364922Z","iopub.status.idle":"2023-02-15T13:30:54.496270Z","shell.execute_reply.started":"2023-02-15T13:30:54.364884Z","shell.execute_reply":"2023-02-15T13:30:54.495113Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_x= pd.read_csv('/kaggle/input/mltfc-gpt/X_train_gpt.csv')\ndf_y= pd.read_csv('/kaggle/input/mlftc/y_train.csv', sep=';')\ndf_corpus = pd.read_csv('/kaggle/input/mlftc/nonlabeled_data.csv', sep=';')","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:54.497561Z","iopub.execute_input":"2023-02-15T13:30:54.498496Z","iopub.status.idle":"2023-02-15T13:30:54.556582Z","shell.execute_reply.started":"2023-02-15T13:30:54.498451Z","shell.execute_reply":"2023-02-15T13:30:54.555691Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import os\nimport nltk\nimport string\nfrom tqdm import tqdm\nfrom time import sleep\nfrom sklearn.model_selection import train_test_split\nfrom french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\nimport re\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\nclass CamembertInputProcessor():\n    def __init__(self,path:str):\n        self.mots = set(line.strip() for line in open(path))\n        self.lemmatizer = FrenchLefffLemmatizer()\n        self.french_stopwords = nltk.corpus.stopwords.words('french')\n    \n    \n\n\n    def text_preprocessing(self, text):\n        \"\"\"\n        Cleaning and parsing the text.\n\n        \"\"\"\n        tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n        nopunc = clean_text(text)\n        tokenized_text = tokenizer.tokenize(nopunc)\n        #remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n        combined_text = ' '.join(tokenized_text)\n        return combined_text\n    \n    def French_Preprocess_listofSentence(self,listofSentence):\n        preprocess_list = []\n        for sentence in listofSentence :\n            #sentence = sentence.replace(\"'\",\" \")\n            #sentence_w_punct = \"\".join([i.lower() for i in sentence if i not in string.punctuation])\n            #sentence_w_num = ''.join(i for i in sentence_w_punct if not i.isdigit())\n            #tokenize_sentence = nltk.tokenize.word_tokenize(sentence_w_num)\n            #words_w_stopwords = [i for i in tokenize_sentence if i not in self.french_stopwords]\n            #words_lemmatize = (self.lemmatizer.lemmatize(w) for w in words_w_stopwords)\n            #sentence_clean = ' '.join(w for w in words_lemmatize if w.lower() in self.mots or not w.isalpha())\n            #sentence_clean = sentence_clean.replace('\\n', '')\n            preprocess_list.append(self.text_preprocessing(sentence))\n        df_test = pd.DataFrame(preprocess_list,columns = {'text'})\n        return df_test\n    \n    def preprocess_chatgpt(self, listofSentence):\n        result = []\n        for text in tqdm(listofSentence, total=len(listofSentence)):\n            resp = api.send_message(text)\n            result.append(resp['message'])\n        df_test = pd.DataFrame(result,columns = {'text'})\n        return df_test\n    \n    \n    def call(self,inputs,labels=None, split=False, type_prep='french'):\n        if type_prep == 'french':\n            df_pre_proc = self.French_Preprocess_listofSentence(inputs)\n        elif type_prep=='no':\n            df_pre_proc = pd.DataFrame({'text': inputs})\n        if labels is not None:\n            df_pre_proc['labels'] = list(labels[[\"category_1\",\t\"category_2\",\t\"category_3\",\t\"category_4\"]].to_numpy())\n        df_pre_proc = df_pre_proc[df_pre_proc.text != '']\n        if split:\n            return train_test_split(df_pre_proc, test_size=0.2, random_state=42, shuffle=True)\n        else:\n            return df_pre_proc\n        ","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:54.558062Z","iopub.execute_input":"2023-02-15T13:30:54.558426Z","iopub.status.idle":"2023-02-15T13:30:55.551491Z","shell.execute_reply.started":"2023-02-15T13:30:54.558391Z","shell.execute_reply":"2023-02-15T13:30:55.550519Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"processor = CamembertInputProcessor('/kaggle/input/dictionnaire-french-words/dictionnaire.txt')","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:55.555460Z","iopub.execute_input":"2023-02-15T13:30:55.555769Z","iopub.status.idle":"2023-02-15T13:30:57.379805Z","shell.execute_reply.started":"2023-02-15T13:30:55.555741Z","shell.execute_reply":"2023-02-15T13:30:57.379053Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train, val = processor.call(df_x.Caption_GPT.tolist(), df_y, split=True, type_prep='french')","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:57.382957Z","iopub.execute_input":"2023-02-15T13:30:57.383295Z","iopub.status.idle":"2023-02-15T13:30:57.420785Z","shell.execute_reply.started":"2023-02-15T13:30:57.383265Z","shell.execute_reply":"2023-02-15T13:30:57.419961Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#train_corpus, val_corpus = processor.call(df_x.Caption_GPT.tolist(), df_y, split=True, type_prep='french')","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:57.422214Z","iopub.execute_input":"2023-02-15T13:30:57.422895Z","iopub.status.idle":"2023-02-15T13:30:57.451517Z","shell.execute_reply.started":"2023-02-15T13:30:57.422853Z","shell.execute_reply":"2023-02-15T13:30:57.450460Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"/kaggle/working/Data/\")","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:57.453004Z","iopub.execute_input":"2023-02-15T13:30:57.453375Z","iopub.status.idle":"2023-02-15T13:30:57.462957Z","shell.execute_reply.started":"2023-02-15T13:30:57.453340Z","shell.execute_reply":"2023-02-15T13:30:57.462066Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train.to_csv('/kaggle/working/Data/train.csv')\nval.to_csv('/kaggle/working/Data/val.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:57.464517Z","iopub.execute_input":"2023-02-15T13:30:57.464932Z","iopub.status.idle":"2023-02-15T13:30:57.497891Z","shell.execute_reply.started":"2023-02-15T13:30:57.464892Z","shell.execute_reply":"2023-02-15T13:30:57.497071Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_corpus, val_corpus = processor.call(df_corpus, split=True, type_prep='french')\ntrain_corpus.to_csv(\"/kaggle/working/Data/train_corpus.txt\", sep=' ', index=False, header = False)\nval_corpus.to_csv(\"/kaggle/working/Data/val_corpus.txt\", sep=' ', index=False, header = False)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:39:31.891088Z","iopub.execute_input":"2023-02-15T13:39:31.891451Z","iopub.status.idle":"2023-02-15T13:39:31.903078Z","shell.execute_reply.started":"2023-02-15T13:39:31.891421Z","shell.execute_reply":"2023-02-15T13:39:31.901799Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"test  = processor.call(pd.read_csv(\"/kaggle/input/mlftc/X_test.csv\", sep=';'))\ntest.index.rename('id',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:30:57.530728Z","iopub.execute_input":"2023-02-15T13:30:57.531185Z","iopub.status.idle":"2023-02-15T13:30:57.542766Z","shell.execute_reply.started":"2023-02-15T13:30:57.531148Z","shell.execute_reply":"2023-02-15T13:30:57.541739Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Définition LM","metadata":{}},{"cell_type":"code","source":"from simpletransformers.language_modeling import LanguageModelingModel\n\ntrain_args = {\n    \"reprocess_input_data\": True,\n    \"overwrite_output_dir\": True,\n    \"output_dir\": str(LM_PATH),\n    \"tensorboard_dir\":'/kaggle/working/tensorboard',\n    \"num_train_epochs\": 1, \n    \"evaluate_during_training\": True,\n    \"evaluate_during_training_verbose\": True,\n    \"save_best_model\": True,\n     \"best_model_dir\": str(LM_PATH_BEST)\n    \n}\n\nlm = LanguageModelingModel(\n    \"camembert\", 'camembert-base', args=train_args, train_files=\"/kaggle/working/Data/train_corpus.txt\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:39:36.298643Z","iopub.execute_input":"2023-02-15T13:39:36.299033Z","iopub.status.idle":"2023-02-15T13:39:41.341335Z","shell.execute_reply.started":"2023-02-15T13:39:36.298999Z","shell.execute_reply":"2023-02-15T13:39:41.339529Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/simpletransformers/language_modeling/language_modeling_model.py:397: UserWarning: use_multiprocessing automatically disabled as camembert fails when using multiprocessing for feature conversion.\n  f\"use_multiprocessing automatically disabled as {model_type}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nos.mkdir('/kaggle/working/Model')\nos.mkdir(LM_PATH)\nos.mkdir(CLASSIF_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:39:41.343634Z","iopub.execute_input":"2023-02-15T13:39:41.344613Z","iopub.status.idle":"2023-02-15T13:39:41.376175Z","shell.execute_reply.started":"2023-02-15T13:39:41.344556Z","shell.execute_reply":"2023-02-15T13:39:41.374364Z"},"trusted":true},"execution_count":46,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1937823861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLM_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLASSIF_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/kaggle/working/Model'"],"ename":"FileExistsError","evalue":"[Errno 17] File exists: '/kaggle/working/Model'","output_type":"error"}]},{"cell_type":"markdown","source":"# Entrainement LM","metadata":{}},{"cell_type":"code","source":"lm.train_model(\"/kaggle/working/Data/train_corpus.txt\", eval_file=\"/kaggle/working/Data/val_corpus.txt\")\n\nlm.eval_model(\"/kaggle/working/Data/val_corpus.txt\")","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:39:41.377120Z","iopub.status.idle":"2023-02-15T13:39:41.377478Z","shell.execute_reply.started":"2023-02-15T13:39:41.377308Z","shell.execute_reply":"2023-02-15T13:39:41.377324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Entrainement Classifier","metadata":{}},{"cell_type":"code","source":"from simpletransformers.classification import (\n    MultiLabelClassificationModel, MultiLabelClassificationArgs\n)\nimport pandas as pd\nimport logging\nlogging.basicConfig(level=logging.INFO)\ntransformers_logger = logging.getLogger(\"transformers\")\ntransformers_logger.setLevel(logging.WARNING)\n\nmodel_args = MultiLabelClassificationArgs(num_train_epochs=10, \n                                          overwrite_output_dir=True,\n                                         max_seq_length=512,\n                                         tensorboard_dir='/kaggle/working/tensorboard',\n                                         evaluate_during_training=True,\n                                         evaluate_during_training_verbose=True,\n                                         save_best_model=True,\n                                         best_model_dir = str(CLASSIF_PATH_BEST))\n\n# Create a MultiLabelClassificationModel\nmodel = MultiLabelClassificationModel(\n    \"camembert\",\n    str(LM_PATH_BEST), # Chemins des poids une fois qu'on aura pré entrainé\n    num_labels=4,\n    args=model_args\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:31:53.567273Z","iopub.execute_input":"2023-02-15T13:31:53.570597Z","iopub.status.idle":"2023-02-15T13:31:58.061247Z","shell.execute_reply.started":"2023-02-15T13:31:53.570540Z","shell.execute_reply":"2023-02-15T13:31:58.060093Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at /kaggle/working/Model/fine-tuned-corpus/best-model were not used when initializing CamembertForMultiLabelSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing CamembertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of CamembertForMultiLabelSequenceClassification were not initialized from the model checkpoint at /kaggle/working/Model/fine-tuned-corpus/best-model and are newly initialized: ['classifier.out_proj.weight', 'roberta.pooler.dense.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nmodel.train_model(train, eval_df= val, output_dir = str(CLASSIF_PATH), roc = roc_auc_score)\nscores2, model_outputs, wrong_predictions = model.eval_model(val, roc=roc_auc_score)\nprint(f\"Epoch finale: {scores2}\")","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:31:58.062686Z","iopub.execute_input":"2023-02-15T13:31:58.065103Z","iopub.status.idle":"2023-02-15T13:36:02.093887Z","shell.execute_reply.started":"2023-02-15T13:31:58.065062Z","shell.execute_reply":"2023-02-15T13:36:02.092591Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/388 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d689f389cbb347878c21380b4ff34e3b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/simpletransformers/classification/classification_utils.py:267: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:207.)\n  labels = torch.tensor(labels, dtype=torch.long)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec1414a8e0554e57b6c222365a4653e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 10:   0%|          | 0/49 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35c401d71aa449ebbe5d15061273562d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69a99f4b3559420abebfcdd823107c46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 10:   0%|          | 0/49 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c118ffebdcd4f7a8bb463bd7689ccc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1018d83ba14e4acc9b536999aaf2c1ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 10:   0%|          | 0/49 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cef030dfa7b44f7bb75b31a0e1e34193"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba6f67730a07478798cbbb5e898e15f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 10:   0%|          | 0/49 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f47db1ca57b4749951693eb6994c9a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d9d48f401a34c22b9a7c3f5784eed90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 4 of 10:   0%|          | 0/49 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2c8423c00c04dbfa7bb4de73cfb7cb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cea288e1cc44edc87e9752c47a00f03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 5 of 10:   0%|          | 0/49 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e63e797d3e2c4402b6fe55156bdf51b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36640a7e43484e79acd2ff42fe41f537"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 6 of 10:   0%|          | 0/49 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51002ea61fb9430b98149a5410a14b6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6fdc943f4344dbdad2a90f9724a4bc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 7 of 10:   0%|          | 0/49 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9c1ad5d00a24a49b1c8b76b8a8bba9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa5b31979dfd4bd1808183627b9f4b40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 8 of 10:   0%|          | 0/49 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9639084195da4047a3328f79fe7be532"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ac3aeba1e684a7f988df99aa811fe73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 9 of 10:   0%|          | 0/49 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38fc299bd4da475e9670767e034f5717"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8359da0545343f58720ec4ef09417bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6423f849e964800a85fd507901a22ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cffd803b2f1c419eb1c66a9559bd9600"}},"metadata":{}},{"name":"stdout","text":"Epoch finale: {'LRAP': 0.890893470790378, 'roc': 0.8774148732593445, 'eval_loss': 0.429966546021975}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Test + submission","metadata":{}},{"cell_type":"code","source":"df_x_test = pd.read_csv('/kaggle/input/mltfc-gpt/X_test_gpt.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:36:20.588775Z","iopub.execute_input":"2023-02-15T13:36:20.589479Z","iopub.status.idle":"2023-02-15T13:36:20.601288Z","shell.execute_reply.started":"2023-02-15T13:36:20.589443Z","shell.execute_reply":"2023-02-15T13:36:20.600271Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df_x_test.Caption_GPT = df_x_test.Caption_GPT.astype(str)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:36:20.879707Z","iopub.execute_input":"2023-02-15T13:36:20.880383Z","iopub.status.idle":"2023-02-15T13:36:20.886351Z","shell.execute_reply.started":"2023-02-15T13:36:20.880346Z","shell.execute_reply":"2023-02-15T13:36:20.885008Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"test = processor.call(df_x_test.Caption_GPT.tolist(), type_prep = 'french')","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:36:24.365942Z","iopub.execute_input":"2023-02-15T13:36:24.366313Z","iopub.status.idle":"2023-02-15T13:36:24.381120Z","shell.execute_reply.started":"2023-02-15T13:36:24.366281Z","shell.execute_reply":"2023-02-15T13:36:24.380029Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = MultiLabelClassificationModel(\n    \"camembert\",\n    str(CLASSIF_PATH_BEST), # Chemins des poids une fois qu'on aura pré entrainé\n    num_labels=4,\n    args=model_args\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:36:29.922906Z","iopub.execute_input":"2023-02-15T13:36:29.923880Z","iopub.status.idle":"2023-02-15T13:36:34.201277Z","shell.execute_reply.started":"2023-02-15T13:36:29.923812Z","shell.execute_reply":"2023-02-15T13:36:34.200283Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"predictions, raw_output  = model.predict(test.text.to_list())","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:36:37.636996Z","iopub.execute_input":"2023-02-15T13:36:37.637385Z","iopub.status.idle":"2023-02-15T13:36:40.101024Z","shell.execute_reply.started":"2023-02-15T13:36:37.637352Z","shell.execute_reply":"2023-02-15T13:36:40.099397Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6141eae63924ccbb7be25bf04cef00e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a92f0fddc05a4806aed650a72a924b56"}},"metadata":{}}]},{"cell_type":"code","source":"df_submission = pd.DataFrame({'Id' : df_x_test['Id '].to_list()})\ndf_submission[['category_1', 'category_2', 'category_3', 'category_4']] = predictions\ndf_submission.to_csv('submission_camember_gpt.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T13:37:20.522778Z","iopub.execute_input":"2023-02-15T13:37:20.523481Z","iopub.status.idle":"2023-02-15T13:37:20.534391Z","shell.execute_reply.started":"2023-02-15T13:37:20.523444Z","shell.execute_reply":"2023-02-15T13:37:20.532947Z"},"trusted":true},"execution_count":40,"outputs":[]}]}